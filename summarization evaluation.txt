News Summarization and Evaluation in the Era of GPT-3
Tanya Goyal1 Junyi Jessy Li2 Greg Durrett1
1 Department of Computer Science 2 Department of Linguistics
The University of Texas at Austin
tanyagoyal@utexas.edu
Abstract
The recent success of zero- and few-shot
prompting with models like GPT-3 has led to
a paradigm shift in NLP research. In this paper, we study its impact on text summarization,
focusing on the classic benchmark domain of
news summarization. First, we investigate
how zero-shot GPT-3 compares against finetuned models trained on large summarization
datasets. We show that not only do humans
overwhelmingly prefer GPT-3 summaries, but
these also do not suffer from common datasetspecific issues such as poor factuality. Next,
we study what this means for evaluation, particularly the role of gold standard test sets. Our
experiments show that both reference-based
and reference-free automatic metrics, e.g. recently proposed QA- or entailment-based factuality approaches, cannot reliably evaluate
zero-shot summaries. Finally, we discuss future research challenges beyond generic summarization, specifically, keyword- and aspectbased summarization, showing how dominant
fine-tuning approaches compare to zero-shot
prompting.
To support further research, we release: (a)
a corpus of 10K generated summaries from
fine-tuned and zero-shot models across 4
standard summarization benchmarks, (b) 1K
human preference judgments and rationales
comparing different systems for generic- and
keyword-based summarization.1
1 Introduction
Fine-tuning pre-trained models on domain-specific
datasets has been the leading paradigm in text summarization research in recent years (Lewis et al.,
2020; Zhang et al., 2020; Raffel et al., 2020). These
models generate high-quality summaries on standard benchmarks, but still require sizeable training datasets to adapt to new settings, e.g., sum-
1All data available at: https://tagoyal.github.io/
zeroshot-news-annotations.html.
GPT-3: Donald Trump's lawsuit against Hillary Clinton, the Democratic
National Committee, and several other individuals and entities has been
dismissed by a federal judge. The judge ruled that Trump's claims are
unsupported by any legal authority and that many of his specific factual
assertions are implausible or unsupported.
CNN article: https://www.cnn.com/2022/09/09/politics/judge-throwsout-trumps-rico-lawsuit-against-hillary-clinton-and-democrats/index.html
GPT-3: Alina Habba is an attorney for Donald Trump. She stated that
Trump will "immediately move to appeal this decision." Habba also said
that the judge's opinion is "rife with erroneous applications of the law" and
that it "disregards the numerous independent governmental investigations
which substantiate our claim that the defendants conspired to falsely
implicate our client and undermine the 2016 Presidential election."
Length-constrained prompt
Keyword-constrained prompt
Summarize the above article in 2 sentences.
Summarize the above article briefly focusing on Alina Habba.
Figure 1: Examples of zero-shot summarization using
GPT-3. We can generate summaries following style
constraints or queries included in the prompts, allowing
us to emulate a range of existing fine-tuned systems.
marizing data from a new source domain or producing a summary in a different style. The success of prompt-based models (GPT-3 (Brown et al.,
2020), T0 (Sanh et al., 2022), PaLM (Chowdhery
et al., 2022), etc.) provides an alternative approach,
namely learning from natural language task instructions and/or a few demonstrative examples in the
context without updating model parameters. While
recent work (Zhao et al., 2021; Min et al., 2022; Ye
and Durrett, 2022) has analyzed and evaluated this
paradigm across a number of tasks, it has only been
studied for text summarization with unreliable automatic metrics (He et al., 2022; Chowdhery et al.,
2022; Ouyang et al., 2022) or in non-standard settings (Saunders et al., 2022).
In this paper, we conduct the first systematic
study of the impact of prompt-based models on
the text summarization research space, using an
Instruct-tuned 175B GPT-3 model (text-davinci-
002) (Brown et al., 2020; Ouyang et al., 2022) as a
case study. Figure 1 shows that GPT-3 summaries
are extremely high-quality and adaptable to different summarization settings. Starting from these observations, we aim to answer three main questions. First, how do prompt-based GPT-3 summaries compare to those obtained from state-ofthe-art fine-tuned summarization models (Zhang
et al., 2020; Liu et al., 2022)? We compare these
approaches using A/B testing on a new corpus of
recent news articles, and find that our study participants overwhelmingly prefer zero-shot GPT-3
summaries across two different “styles” with different prompts (three-sentence and single-sentence).
Moreover, these zero-shot summaries do not suffer
from limitations due to low-quality training data
that plague fine-tuned generic summarization models (Maynez et al., 2020; Goyal et al., 2022).
Second, are existing automatic metrics wellsuited to evaluating zero-shot summaries? Recent work has shown that classic reference-based
such as ROUGE (Lin, 2004) and BERTScore (Zhang*
et al., 2020) are unreliable when small improvements are reported (Peyrard, 2019; Fabbri et al.,
2021); however large differences, on the order of
say 5 ROUGE points or greater, are considered to
be correlated with human preferences (Bhandari
et al., 2020; Deutsch et al., 2022). However, we
find that the same is no longer true when evaluating zero-shot GPT-3 summaries. These summaries
score much lower on automatic metrics (7 ROUGE-L
points on average) than all prior state-of-the-art
models while comfortably outperforming them on
human evaluation. Furthermore, we show that recent reference-free metrics, e.g. QA-based metrics (Fabbri et al., 2022; Durmus et al., 2020) and
trained factuality models (Kryscinski et al., 2020;
Goyal and Durrett, 2020), similarly fail to adapt to
this shift from the fine-tuned to zero-shot summarization space and need to be re-visited.
Finally, how can zero-shot summaries be used
for use cases beyond generic summarization? We
focus on keyword-based and aspect-based summarization. For keyword-based summarization, we
find that zero-shot GPT-3 consistently generates
more coherent and keyword-relevant summaries
compared to current fine-tuned alternatives: crowd
annotators prefer GPT-3 summaries over a baseline model (He et al., 2020) 70% of the time. We
observe mixed results for the aspect-based setting, where GPT-3 summaries show frequent failure cases when prompted with simple prompts for
aspect-based summarization.
Taken together, this evidence suggests that GPT-
3 represents a fundamental paradigm shift in summarization, changing the what data we need (or
don’t need) and what approaches we can now explore. Evaluating these systems as they progress
further will require a new framework distinct from
the automatic metrics that have dominated the last
decade of summarization research.
2 Models and Setup
2.1 Current Paradigms for Summarization
Recent zero- and few-shot prompting based models (Brown et al., 2020; Sanh et al., 2022), have
shown impressive generalization capabilities on
unseen tasks specified using prompts alone and
without performing any gradient updates (Mishra
et al., 2022). In this work, we want to compare
their text summarization performance against the
current state-of-the-art models.
Pre-trained LM
(Task-specific models
trained for each dataset)
Fine-tuned on
summ. datasets
Instruction-tuned on
multiple tasks
Zero-shot prompting
Zero-shot prompting
‣ BART
‣ PEGASUS
‣ T5
‣ CTRLSum
‣ T0
‣ FLAN
‣ Instruct-GPT
‣ GPT-3
‣ PaLM
‣ Turing-NLG
(Not available or less
effective than
instruction-tuned
counterparts)
(these not trained
on standard summ.
datasets)
‣text-davinci-002
‣ BRIO
Summarization datasets
used during training
Figure 2: Broad categorization of available summarization systems; those compared in this work are highlighted in red.
Figure 2 shows the broad categories of all available summarization approaches, including current
SOTA models and prompting-based models. The
former set consists of fine-tuned language models, trained on a large number of article-summary
pairs (e.g. BART (Lewis et al., 2020), PEGASUS
(Zhang et al., 2020), BRIO (Liu et al., 2022)) to
obtain dataset-specific systems. This category also
includes models aimed at tasks beyond generic
summarization, such as keyword- or query-based
summarization, that still rely on standard datasets
for training (He et al., 2020).
On the other extreme are zero- or few-shot
models, (e.g. GPT3 (Brown et al., 2020), PaLM
(Chowdhery et al., 2022)), that are not explicitly
trained for any particular task, as discussed above.
Recent work (Ouyang et al., 2022; Wei et al., 2022;
Sanh et al., 2022) has improved on these models
by introducing instruction-tuned models. Here,
pre-trained language models are fine-tuned on multiple tasks (which may include summarization) using instruction templates in order to align their training with inference time usage.
In this work, we compare the summarization
performance of three models that are representative
of this space of options:
1. OpenAI’s text-davinci-002, a GPT-3 model
(Brown et al., 2020) from the Instruct series
(Ouyang et al., 2022). While we do not know
the exact training details for this release of
the model, the previous in the series (textdavinci-001) was fine-tuned on a combination of prompts submitted to their API and labeler prompts spanning multiple tasks. These
tasks include summarization but not (to our
knowledge) standard summarization datasets
like CNN/DM (Hermann et al., 2015; Nallapati
et al., 2016) or XSum (Narayan et al., 2018).
We choose the text-davinci-002 version for our
experiments in order to benchmark the best
available prompt-based model.2 We refer to
this approach as GPT3-D2.
2. BRIO (Liu et al., 2022), a fine-tuned summarization model that reports state-of-the art results
on both CNN/DM and XSum. We will use versions
of this model fine-tuned on each of these two
datasets.
3. T0 (Sanh et al., 2022), a prompt-based model
fine-tuned on multiple tasks including standard
summarization datasets. This provides a useful
point of comparison between task-specific finetuned (BRIO) and zero-shot models (GPT3-D2).
2.2 Using GPT3-D2 for zero-shot
summarization
Fine-tuned models largely follow the “style” of reference summaries in their training data, and hence,
2We did not observe obvious quality differences in generated summaries between text-davinci-001 and text-davinci-
002. Examples are included in Appendix C.
The three African nations on the UN Security Council condemned reports
of discrimination against African citizens at the Ukrainian border during a
meeting at the UN HQ in New York City Monday.
The United Nations Security Council condemned the reports of
discrimination against African citizens at the Ukrainian border. The African
Union has said it is "disturbed" by the reports of segregation against
Africans in Ukraine, which it described as "shockingly racist."
The article discusses the reports of discrimination against African citizens
at the Ukrainian border. The representatives from the three African nations
on the UN Security Council condemned the reports and called for the
mistreatment of African peoples on Europe's borders to cease immediately.
Foreign students attempting to flee Ukraine after Russia invaded the
country told CNN that they experienced racial discrimination at the
Ukrainian border.
Prompt: Summarize the article in N sentences.
N = 3 N = 2 N = 1
Article: https://www.cnn.com/2022/03/01/africa/africa-condemnsracism-ukraine-intl/index.html
Figure 3: Illustration of length control using the task description / prompt for GPT3-D2. We found that the generated summaries followed the given sentence length
constraint 98% of the time, allowing us to generate different length summaries emulating different datasets.
generated summaries show large variance between
datasets (see Table 1 for basic summary statistics
of standard summarization datasets). To ensure fair
comparison between these and zero-shot GPT3-D2,
we adapt the latter’s prompt to align with datasetspecific styles.
Specifically, we follow prior work (Sanh et al.,
2022) and use sentence-count length prompts to
adapt to each dataset. Although these datasets also
differ along other attributes, e.g. CNN/DM is leadbiased whereas XSum requires inferences drawing
from a whole article, we do not attempt to control any other attributed of the summary. Figure 3
shows an example of different length GPT3-D2 summaries for the same news article, using the following prompt format:3
Article: {{article}}
Summarize the above article in N sentences.
We found that GPT3-D2 summaries faithfully follow the given length constraint in 98% of the test
instances used in our human study data in Section 3.
Given this setup, we first compare the summary
quality of the three summarization models through
a human annotation study (Section 3). Then, we
evaluate the current suite of summarization metrics
for zero-shot summarization (Section 4). Finally, in
3Although prior work has shown that few-shot learning
works better than zero-shot across tasks like inference, textual
reasoning, and translation (Brown et al., 2020; Chowdhery
et al., 2022; Ouyang et al., 2022; Sanh et al., 2022), we opt
for zero-shot prompting as news articles are generally longer
and multiple demonstration may not fit within the context Section 5, we briefly discuss GPT3-D2 performance
on summarization tasks beyond generic summarization and new challenges.
3 Human evaluation of GPT3-D2
summaries
Generated summaries of fine-tuned models (Lewis
et al., 2020; Zhang et al., 2020; Liu et al., 2022)
emulate gold-standard summaries in their training
datasets. In contrast, prompt-based GPT3-D2 models generate summaries based on how the given
task description surfaces behavior learned during
pre-training or instruction-tuning. In this section,
we ask: how do these paradigms compare? Does
learning from gold summaries lead to a better summarization model? To answer this, we conduct a
human study to compare outputs of our 3 representative models and collect human preferences of
quality.
3.1 Experimental Setup
Datasets for fine-tuning We choose two standard fine-tuning datasets whose summaries differ
along multiple dimensions such as length and abstractiveness:
1. CNN/DM (Hermann et al., 2015; Nallapati
et al., 2016) contains reference summaries that
are approximately 3-4 sentences long. Summaries in this dataset are highly extractive and
lead-biased.
2. XSum (Narayan et al., 2018) contains 1 sentence summaries of BBC news articles. In
this dataset, references summaries, and consequently generated summaries from fine-tuned
models are highly abstractive.
Datasets for evaluation Because GPT3-D2’s pretraining and instruction-tuning datasets are unknown, it may have been trained on existing articles
and summaries in the test splits of these standard
benchmarks. We therefore run our human study on
100 recent articles from CNN4 and BBC, collected
between March 1, 2022 and June 31, 2022. We call
these CNN-2022 and BBC-2022 respectively.
4Although the BRIO’s CNN/DM model also includes DailyMail data in its training, we do not use this news source in
our study as it is now widely considered to be unreliable. E.g.
according to Media Bias / Fact Check site, DM’s factual reporting is rated ‘low’ https://mediabiasfactcheck.com/
daily-mail/.
Model details We use the publicly released
BRIO-XSum and BRIO-CNN/DM models to generate
summaries.5 For T0, we use a prompt we selected
from its prompt repository for CNN/DM and XSum
datasets.6 Finally, to generate GPT3-D2 summaries,
we set N = 3 for CNN and N = 1 for BBC in
our standard sentence-count prompt template from
Section 2.
For a maximally fair comparison in this “realistic” setting, we take some additional steps to improve the output of BRIO-XSum. In order to automate dataset creation, XSum removes the first sentence from news articles to use as the gold summary
for training, then treats the rest of the sentences as
the article to summarize. This setup differs from
the real world usage of summarization systems
where the complete article is summarized. Due
to this mismatch, BRIO-XSum often generates very
low quality outputs, e.g. All images: Strule Shared
Education Campus in Figure 4, for around 30% of
the articles. We manually identify these examples
and first attempt to fix them by selecting a summary
without such obvious failures from further down
the beam (we use beam size = 10). However, if we
cannot find a “better” summary, we remove the first
sentence of the article and re-sample a new summary to align with its noisy training. This latter
strategy often results in factually incorrect summary generations, as is well documented in prior
research (Maynez et al., 2020; Goyal and Durrett,
2021).
Design of the human study We design an A/B
test to collect preference annotations. For each
given article, annotators are shown summaries from
all three summarization systems (BRIO, T0 and
GPT3-D2). They are then asked to select their most
and least preferred summary or summaries. In addition to these multiple choice questions, we also
ask for a free-text justification of both choices.
We make two design decisions for our human
study: first, we do not provide annotators with specific definitions of summary quality to avoid introducing our own biases. It is also quite challenging
to produce a unified definition of quality for the
very different “styles” of summaries evaluated in
this study. Instead, we ask them to rely on their
own preferences based on summaries they would
like to see if they were browsing the web, which
5Models at: https://github.com/yixinL7/BRIO
6Repository with T0 prompts: https://github.com/
bigscience-workshop/promptsource 
CNN Article: (CNN) Mortgage rates fell slightly this week,
marking the third consecutive week of declines. But with rates
hovering above 5% and home prices well above where they
were this time last year, prospective buyers are finding it
increasingly difficult to afford a home. The 30-year, fixed-rate
mortgage averaged 5.09% in the week ending June 2, down
from 5.10% the week before, according to Freddie Mac. It is
still well above the 2.99% average from this time last year. […]
Rising prices had already been pushing many prospective
buyers to the sidelines […] The Fed has been seeking to tame
inflation by raising interest rates over the past couple of
months. And the central bank has signaled there are more rate
hikes to come. […]
The 30-year, fixed-rate mortgage averaged 5.09% in the week ending
June 2. It's the third consecutive week of declines. But rates are still
above 5% and home prices are well above where they were this time last
year. Rising prices have pushed some prospective buyers to the sidelines.
30-year, fixed-rate mortgage averaged 5.09% in the week ending June 2.
It is still well above the 2.99% average from this time last year. Rising
prices had already been pushing many prospective buyers to the sidelines.
BBC Article: The full opening of a landmark shared education
campus in Omagh is facing another delay. Education Minister
Michelle McIlveen has now said the Strule Shared Education
Campus is planned to open in September 2026. The minister
clarified the new date in response to an assembly question
from the SDLP MLA Daniel McCrossan. The campus had
originally been due to open in 2020, but has been delayed a
number of times. The estimated cost of the project has also
risen substantially to about £230m according to figures
previously released by the minister in November 2021. […]
BRIO
T0
GPT3
The Strule Shared Education Campus is facing another delay, and is now
planned to open in September 2026.
All images: Strule Shared Education Campus.
After removing first sentence of input article: The full opening of the
Strule shared education campus in Omagh, County Tyrone, has been
delayed to September 2026.
Strule, Northern Ireland's biggest ever school-building project, is now
scheduled to open in 2026, the Education Minister has said.
BRIO
T0
GPT3
Figure 4: Examples of CNN-style and BBC/XSum-style summaries for the three systems. For CNN, we observe
that models fine-tuned on the CNN/DM training set reflect its dataset biases; summaries are highly extractive, specific
and lead-biased. On the other hand, GPT3-D2 summaries contain fewer specific details but cover more content.
we believe to be a representative scenario for nonexpert consumers of news summaries. Detailed
task instructions are included in Appendix F.
Second, we allow multiple selections for both the
best and worst summary questions to cater to scenarios in which different summarization systems
output similar quality summaries without meaningful differences.
We hire crowd annotators through Prolific. For
both CNN and BBC, we recruit 60 unique participants to annotate the 100 summaries in each dataset.
Each annotator was asked to annotate 5 articles and
each article was annotated by 3 annotators. Additionally, we use the Prolific’s demographic filters to
restrict participation to USA (or UK) residents for
CNN (or BBC). We anticipate that residents from
these respective countries are better positioned to
understand country-specific news events and evaluate their summaries. Participants were paid approximately $11/hr for their work.
3.2 Results
Differences between summarization systems
Figure 4 shows examples of generated summaries
from all three summarization systems for both
CNN and BBC articles. For CNN, we observe that
fine-tuned BRIO summaries tend to be highly extractive and generally include a high number of named
entities (dates, percentages, names), reflecting the
data it was trained on. In contrast, GPT3-D2 sumModel Length Statistics % novel n-gms #NEs per
#sent #words/sent n = 1 n = 2 100 words
CNN
BRIO 3.7 15.8 12.1 36.2 12.9
T0 2.7 14.9 16.4 45.2 12.8
GPT3-D2 2.9 23.4 16.3 40.7 10.5
BBC
BRIO 1.0 20.2 24.6 61.2 9.1
T0 1.0 20.0 26.3 66.7 9.8
GPT3-D2 1.0 27.7 16.4 42.3 8.5
Table 2: Statistics for generated summaries evaluated
in the human study across all datasets and summarization systems. We observe that GPT3-D2 generated summaries nearly always follow the sentence length constraints in their prompts.
maries are more abstractive and less specific, but
provide a more exhaustive overview of the article
content. Table 2 provides quantitative evidence of
this; we use percentage of novel n-grams to measure abstractiveness, and number of named entities
per 100 words to measure specificity.
For BBC, we observe inverse trends where
BRIO and T0 are more abstractive compared to
GPT3-D2. Again, this can be attributed to the XSum
training data used to train both these prior models. For GPT3-D2 summaries, on the other hand,
the level of abstractiveness does not differ between
datasets. Finally, Table 2 shows that GPT3-D2 summaries tend to have longer sentences, and therefore
